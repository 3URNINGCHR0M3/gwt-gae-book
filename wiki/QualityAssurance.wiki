#summary Quality assurance

So far we developed a [http://cultureshows.appspot.com/ basic app], which allows signing in with OpenID and managing performances schedule. Before we add more features, we need to look more at quality.

<wiki:toc max_depth="2" />


= Pre-requisites =
 * Make sure you have [http://code.google.com/p/gwt-gae-book/downloads/detail?name=CultureShows-0.3-before-QA.tgz the latest source code] for this chapter
 * [http://en.wikipedia.org/wiki/Quality_assurance General quality assurance]
 * [http://en.wikipedia.org/wiki/Software_quality Software quality]

= When should QA start? =
If you answered at unit tests, or right at the beginning of development with [http://en.wikipedia.org/wiki/Test-driven_development Test-driven development], think again. What if you deliver a bug-free, but useless project to your customer?

QA should start when we [SoYouHaveAnIdea start defining requirements]. The later we fix defects, the more costly they are. A bad user story is much easier to fix before we actually implement it.

Let's see how we can increase quality for the main phases in a software project. Note that this is an iterative process which repeats continuously throughout the project lifetime, rather than being done in a [http://en.wikipedia.org/wiki/Waterfall_model waterfall] way.

= Personae =
When defining [http://en.wikipedia.org/wiki/Persona_(marketing) user personae], consider your intended audience. Then search, meet and discuss with a few representatives for each of the draft personae you described so far. Understand their behavior patterns, environment, skills and needs, and include these in persona description.

*Additional resources*
 * [http://www.designstamp.com/downloads/DesignStamp_PersonaProcess.pdf The Persona Process]

= User stories =
Having a good idea of personae life goals, experience goals and end goals, we can start [SoYouHaveAnIdea defining user stories] that contribute to accomplishing those goals.

One of the best ways to validate stories and prioritization is to share them with personae representatives. List all the stories (removing "As Persona") and ask them to rate their importance. Discuss why they rated it that way. The lowest rated stories should probably be completely removed from your backlog.
Ask what's missing to help them accomplish their goals, and rate the importance of those stories too. 

Rather than having a huge list of features demanded by all potential users you talk to, try to determine the minimum feature set required to get early customers. [http://www.businessweek.com/magazine/content/07_26/b4040436.htm Fail fast, fail cheap].

*Additional resources*
 * [http://www.slideshare.net/craigwbrown/invest-in-good-user-stories-presentation INVEST in user stories]
 * <a href="http://www.amazon.com/gp/product/0976470705?ie=UTF8&tag=gwtgaebook-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0976470705">The Four Steps to the Epiphany</a><img src="http://www.assoc-amazon.com/e/ir?t=gwtgaebook-20&l=as2&o=1&a=0976470705" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /> : customer discovery, customer validation, customer creation, company building
 * [http://www.startuplessonslearned.com/ Startup lessons learned blog]


= Metrics and KPIs =
They say "You can’t improve what you can’t measure". If we're asked "How is the project doing?" and reply "Good", a follow-up question might be "What do you understand by good?". Common project metrics include 
 * Schedule - estimated/targeted delivery date and slippage in days
 * Cost - actual budget versus original budget
 * Resources - what resources and much of them are we using (people, time, equipment...)

Using Scrum allows quick (bi-weekly to monthly) inspection of these, and adapting.

[http://en.wikipedia.org/wiki/Performance_indicator Key Performance Indicators] give us more specific indicators on how we stand on areas important to our project. Some of the Culture Shows KPIs are:
 * visitors of the landing page
 * users signing in
 * users scheduling performances
 * 3rd party sites displaying performances
 * active theaters (having regular performances)

[http://en.wikipedia.org/wiki/Net_Promoter Net Promoter Score] is a relatively recent and simple metric for [http://en.wikipedia.org/wiki/Customer_satisfaction customer satisfaction].

*Additional resources*
 * [http://www.theultimatequestion.com/theultimatequestion/measuring_netpromoter.asp?groupcode=2 Measuring Net Promoter Score]

= User interface =
We've already covered [VisualizingYourApp building mockups] and getting feedback on them. 

A fast and cheap technique for [http://en.wikipedia.org/wiki/Usability_testing usability testing] is to print all the mocked screens of the app, then going with prints to potential users. After giving a basic context, present the landing page print asking questions such as "what do you think this is", "what would you do next", "how would you do that". Be careful to avoid direct instructions such as "Now please schedule a performance" (the button is obvious).

According to their actions, present the corresponding screen print. If they want to fill out form fields, ask them to do that with a pen, and fill it yourself too on the next screen where that data appears. Investing a few days in preparing and performing this research will save weeks later.

*Additional resources*
 * <a href="http://www.amazon.com/gp/product/0321344758?ie=UTF8&tag=gwtgaebook-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0321344758">Don't Make Me Think: A Common Sense Approach to Web Usability</a><img src="http://www.assoc-amazon.com/e/ir?t=gwtgaebook-20&l=as2&o=1&a=0321344758" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /> (great book)
 * <a href="http://www.amazon.com/gp/product/0672326140?ie=UTF8&tag=gwtgaebook-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0672326140">The Inmates Are Running the Asylum: Why High Tech Products Drive Us Crazy and How to Restore the Sanity</a><img src="http://www.assoc-amazon.com/e/ir?t=gwtgaebook-20&l=as2&o=1&a=0672326140" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />

= Functional specifications =
[http://en.wikipedia.org/wiki/Functional_specification Functional specifications] detail the application from users point of view. It helps making sure all stakeholders (from customers to engineers) have the same understanding of the expected behavior.

A functional specification might include details about user interface (UI), behaviors, expected performance, internationalization and privacy requirements, constraints and limitations, interaction with other systems.

[http://en.wikipedia.org/wiki/Software_peer_review Peer reviews], with varying degrees of formality, help in discovering defects.

*Additional resources*
 * [http://www.joelonsoftware.com/articles/fog0000000036.html Painless Functional Specifications]
 * [http://vast.uccs.edu/~tboult/CS330/DOCS/Requirements%20Review%20Checklist.doc Example Requirements Review Checklist]

= Design/technical specifications =

[http://en.wikipedia.org/wiki/Software_design Design specifications] explain how the application works from engineering point of view. What should go into it? Topics vary from project to project and might include architecture, data models, logic, internationalization, testability, testing recommendations (just what's not obvious from functional specification), performance, security. As a guideline, I like to think about
 * what helps to clarify and estimate how one would implement this feature, before writing code
 * what would I find helpful if I come back to this project/functionality after six months
 * if I was a new team member, what would help me getting ready for changing existing features or implementing new ones

I might be old school, but I like doing pseudocode first for complex functionality. [Authentication#Design_of_handling_both_anonymous_and_authenticated_users We saw] how this saved us from investing into actual code writing, debugging and testing which would have been thrown away later. Pseudocode also gives a higher-level overview on how various components works. Keep it updated as the project develops, to be used later as a reference by you and others.

[http://en.wikipedia.org/wiki/Software_peer_review Peer reviews] with fellow engineers  are extremely useful for early defect discovery. Keeping a history of found defects and spent time helps balancing the allocated review time for best return of investment. If reviews find almost no defects, the author is either a great engineer, or the reviews aren't effective.


= Code =


== Static code analysis tools ==
[http://en.wikipedia.org/wiki/Static_code_analysis Static code analysis] tools scan code and report various possible issues, from code formatting style to bugs. Go through [http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#Java the list of Java tools] and see what would benefit you most. Setup the tools to run as part of the build process, after every commit (you are using [http://en.wikipedia.org/wiki/Continuous_integration continuous integration], right?).

Running PMD on Culture Shows code found nothing. !FindBugs though discovered these small issues:
 * Constants.manageActionType should start with an uppercase letter
 * Main.logger should be final
 * Dead store to local variable in !GetUserInfo, the value is not read or used in any subsequent instruction:
{{{
memberKey = datastore.store(member);
}}}
and several false positives (the tool gives more details, but copy-pasting exact issue report doesn't work (!)).


== Code reviews ==
Effective [http://en.wikipedia.org/wiki/Code_review code reviews] are one of the most handy methods to increase code quality. [http://www.google.com/search?sourceid=chrome&ie=UTF-8&q=code+review+code.google Code review tools] ease the interaction between engineers and offer integrated comments and defects tracking.

*Additional resources*
 * <a href="http://www.amazon.com/gp/product/020161622X?ie=UTF8&tag=gwtgaebook-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=020161622X">The Pragmatic Programmer: From Journeyman to Master</a><img src="http://www.assoc-amazon.com/e/ir?t=gwtgaebook-20&l=as2&o=1&a=020161622X" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />
 * [http://misko.hevery.com/code-reviewers-guide/ Code reviewers guide] (focused on Java)
 * [http://www.basilv.com/psd/blog/2007/strategies-for-effective-code-reviews Strategies for effective code reviews]


= Testing =

Here are more details about what [http://en.wikipedia.org/wiki/Software_testing testing] can be performed. We'll focus only on a few of these.

[http://en.wikipedia.org/wiki/Software_peer_review Peer reviews] should again be used in the areas below to discover where testing could be improved.


== Unit testing ==

As we'll keep adding and changing features, how can we know if we break existing functionality? This is where automated tests, such as [http://en.wikipedia.org/wiki/Unit_testing unit testing], come in. 

Another benefit is that we'll accomplish a better design of our code just by making it unit testable. For example, [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/server/dispatch/ManagePerformanceHandler.java?r=584 ManagePerformanceHandler] has now one big method doing everything, which is harder to follow and debug. `createPerformance()` and `onUserInfoAvailable()` in [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/client/landing/LandingPresenter.java?r=584 LandingPresenter] access cookies directly from browser, so we can't switch cookie storage with something else, say [http://diveintohtml5.org/storage.html HTML5 storage], or run tests from command line where we don't have a browser.

Unit testing focus only on the smallest, independent units of our code. [http://en.wikipedia.org/wiki/Proton Protons] and [http://en.wikipedia.org/wiki/Neutron neutrons] you say? Well, not _that_ small. We need to look at parts which have logic which could be tested. If they interact with other components, such as storage, we need to replace those parts with [http://en.wikipedia.org/wiki/Mock_object mock objects]. Methods suitable for unit testing should take an input, do something with it, and provide an output. We'll test them by providing known inputs and checking if outputs match what we expected.

=== Exercise ===
Review [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/server/dispatch/ManagePerformanceHandler.java?r=584 ManagePerformanceHandler] and identify parts which should be unit tested. Remember we are testing the logic of these parts. A simple block of code which just stores an object in the datastore and returns it doesn't have anything to be meaningfully unit tested.

=== Exercise solution ===
If we're trying to update or delete a performance, we expect to be given valid theater and performance keys:
{{{
		case UPDATE:
		case DELETE:
			...
			if (!Strings.isNullOrEmpty(action.getPerformance().performanceKey)) {
				try {
					performanceKey = KeyFactory.stringToKey(action
							.getPerformance().performanceKey);
				} catch (Exception e) {
					// invalid key, ignore it
				}
			}

			if (null == performanceKey) {
				return new ManagePerformanceResult("Invalid performance key",
						null);
			}

			performance = datastore.load(performanceKey);
}}}

This is something we could isolate in a separate method
{{{
	public static Key getValidDSKey(String key)
}}}
which would throw an exception when the key is null, empty or invalid. Why not [http://tutorials.jenkov.com/java-exception-handling/validation-throw-exception-or-return-false.html return an error] or [http://download.oracle.com/javase/6/docs/technotes/guides/language/assert.html use asserts]? As [http://download.oracle.com/javase/6/docs/technotes/guides/language/assert.html preconditions checking] advise, the keys are passed to the `public execute()` as part of the input, so we should enforce the argument checks in a way understandable by the caller of this method.

Here are the [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/server/util/Validation.java validation method]
{{{
	public static Key getValidDSKey(String key) {
		if (Strings.isNullOrEmpty(key)) {
			throw new IllegalArgumentException("Null or empty key");
		}

		Key dsKey;
		try {
			dsKey = KeyFactory.stringToKey(key);
		} catch (Exception e) {
			throw new IllegalArgumentException("Invalid key " + key);
		}
		
		return dsKey;
	}
}}}

[http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/test/org/gwtgaebook/CultureShows/server/util/ValidationTest.java the test]
{{{
	@Test
	public final void getValidDSKeyTest() throws Exception {
		try {
			Validation.getValidDSKey(null);
			fail("Null key was considered valid");
		} catch (IllegalArgumentException expected) {
			// exception thrown, we're good, nothing else to check here
		}

		try {
			Validation.getValidDSKey("");
			fail("Empty key was considered valid");
		} catch (IllegalArgumentException expected) {
			// exception thrown, we're good, nothing else to check here
		}

		final String invalidKey = "invalidKey";
		try {
			Validation.getValidDSKey(invalidKey);
			fail("Invalid key " + invalidKey + " was considered valid");
		} catch (IllegalArgumentException expected) {
			assertTrue("Exception message doesn't mention " + invalidKey,
					expected.getMessage().indexOf(invalidKey) >= 0);
		}

		// any appengine key will work
		final String validKey = "agxjdWx0dXJlc2hvd3NyDgsSB1RoZWF0ZXIY4V0M";
		Key dsKey;
		dsKey = Validation.getValidDSKey(validKey);
		assertTrue("Returned key is null", null != dsKey);
		assertTrue("Returned key " + dsKey.toString() + " is not equal to "
				+ validKey, dsKey.equals(KeyFactory.stringToKey(validKey)));

	}
}}}


and [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/server/dispatch/ManagePerformanceHandler.java?r=591 the slightly refactored code].

=== Exercise ===
Review [http://code.google.com/p/gwt-gae-book/source/browse/trunk/CultureShows/src/org/gwtgaebook/CultureShows/client/landing/LandingPresenter.java?r=584 LandingPresenter] and identify parts which should be unit tested.

=== Exercise solution ===




mockito


*Additional resources*
 * [http://www.vogella.de/articles/JUnit/article.html JUnit tutorial]
 * [http://code.google.com/p/gwt-platform/wiki/UnitTesting gwt-platform unit testing introduction]
 * [http://www.c2.com/cgi/wiki?CodingJavaUnitExceptionTests Coding Java Unit Exception Tests]
 * [http://en.wikipedia.org/wiki/Test-driven_development Test-driven development]
 * http://misko.hevery.com/presentations/

== Integration testing ==

After we unit tested parts of functionality, [http://en.wikipedia.org/wiki/Integration_testing integration testing] checks if these parts work together.


public void delete(String performanceKey)
validateKey(performanceKey)
memberKey = getMember() 
//how to do this in a clear, performance/cachable, secure way? 
//passing memberKey string means we'll check it again for validity when we know it came from app engine. UserInfo should be mockable, or when passing member to private methods skip checking??



performance.load(key).filter(belongs to a theater owned by member)


== UI testing ==
Selenium
http://www.opensourcetesting.org/

*Additional resources*

== API testing ==

!jMeter

*Additional resources*

== Performance testing ==
is client first load waiting for server to say if signed in or not? Assume no and update UI when response received. 


http://www.uselessapplications.com/en/Application/FirefoxThrottle.aspx
chrome Speed Tracer are asta?



webpagetest.org

generate from server a page containing ClientState obj?
http://code.google.com/webtoolkit/articles/dynamic_host_page.html





*Additional resources*


== Manual test cases  ==
Finally, there are situations when automating some tests isn't cost effective. These [http://en.wikipedia.org/wiki/Test_case test cases] should be documented so one can run them whenever needed.


== Additional resources ==
 * [http://googletesting.blogspot.com/ Google testing blog]
 * [http://en.wikipedia.org/wiki/A/B_testing A/B testing]
 * [https://www.google.com/analytics/siteopt Google website optimizer]



= Other areas =
Quality should be considered in all project areas, not just software development. These include deployment, data centers management (monitoring availability, performance), support, marketing.






<wiki:comment>NAV_START</wiki:comment>
<a href='http://code.google.com/p/gwt-gae-book/issues/entry'><img src='http://gwt-gae-book.googlecode.com/svn/wiki/assets/envelope.png' border='0' title='Send feedback' /></a>
<img src='http://gwt-gae-book.googlecode.com/svn/wiki/assets/spacer.png' border='0' />
<a href='http://code.google.com/p/gwt-gae-book/wiki/ManagingPerformances'><img src='http://gwt-gae-book.googlecode.com/svn/wiki/assets/prev.png' border='0' title='Previous chapter: Updating and deleting performances' /></a>
<a href='http://code.google.com/p/gwt-gae-book/wiki/TableOfContents'><img src='http://gwt-gae-book.googlecode.com/svn/wiki/assets/contents.png' border='0' title='Table Of Contents' /></a>
<a href='http://code.google.com/p/gwt-gae-book/wiki/LandingEnhancements'><img src='http://gwt-gae-book.googlecode.com/svn/wiki/assets/next.png' border='0' title='Next chapter: Landing page enhancements' /></a>
<wiki:comment>NAV_END</wiki:comment>